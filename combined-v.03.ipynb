{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import torch.nn\n",
    "import statistics\n",
    "import torch.utils\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dataframe = pandas.read_csv('onion-or-not.csv', encoding='utf-8', nrows=500)\n",
    "input_dataframe = pandas.read_csv('onion-or-not.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_vector = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in input_dataframe.index:\n",
    "    tokenized_vector[i] = nltk.word_tokenize(input_dataframe.loc[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in tokenized_vector:\n",
    "    for counter, token in enumerate(tokenized_vector[tokens]):\n",
    "        if stemmer.stem(tokenized_vector[tokens][counter]) not in stopwords:\n",
    "            tokenized_vector[tokens][counter] = stemmer.stem(tokenized_vector[tokens][counter])\n",
    "        else:\n",
    "            tokenized_vector[tokens].remove(tokenized_vector[tokens][counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tokenized_vector = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokenized_vector:\n",
    "    preprocessed_tokenized_vector.append(' '.join(tokenized_vector[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(preprocessed_tokenized_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_df = pandas.DataFrame(X.todense(), columns=vectorizer.get_feature_names(), dtype=numpy.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = pandas.concat([tf_idf_df, input_dataframe.iloc[:, 1:]], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of dataframe:  1012.99 MB\n"
     ]
    }
   ],
   "source": [
    "print('Total size of dataframe: ', round(sys.getsizeof(preprocessed_data) / 2**20, 2), 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tf_idf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del preprocessed_tokenized_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del input_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/andreas/Documents/data_mining/project/onion/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pandas.DataFrame(preprocessed_data.columns[:-1].tolist(), columns=['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pandas.concat([preprocessed_data.iloc[:, -1], abs(preprocessed_data.iloc[:, -1] - 1)], axis=1).astype(numpy.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.columns = ['valid', 'fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fit, x_test, y_fit, y_test = \\\n",
    "    sklearn.model_selection.train_test_split(X, Y,\n",
    "                                             test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = \\\n",
    "    sklearn.model_selection.train_test_split(x_fit,\n",
    "                                             y_fit,\n",
    "                                             test_size=0.10,\n",
    "                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an identity matrix X with dimentions 943x943\n",
    "x_train = torch.from_numpy(x_train.to_numpy()).float()\n",
    "# convert target values to pytorch tensor\n",
    "y_train = torch.from_numpy(y_train.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a pytorch dataset instance from X and Y variables\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an identity matrix X with dimentions 943x943\n",
    "x_val = torch.from_numpy(x_val.to_numpy()).float()\n",
    "# convert target values to pytorch tensor\n",
    "y_val = torch.from_numpy(y_val.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a pytorch dataset instance from X and Y variables\n",
    "val_dataset = torch.utils.data.TensorDataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an identity matrix X with dimentions 943x943\n",
    "x_test = torch.from_numpy(x_test.to_numpy()).float()\n",
    "# convert target values to pytorch tensor\n",
    "y_test = torch.from_numpy(y_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a pytorch dataset instance from X and Y variables\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an identity matrix X with dimentions 943x943\n",
    "X = torch.from_numpy(X.to_numpy()).float()\n",
    "# convert target values to pytorch tensor\n",
    "Y = torch.from_numpy(Y.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X.shape[1], 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    device = None\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=22125, out_features=512, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (5): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = False\n",
    "# initialize early stopping prevention limit\n",
    "prevent = 5\n",
    "# initialize early stopping prevention limit\n",
    "consecutive = False\n",
    "# initialize early stopping message\n",
    "message = ' '\n",
    "# initialize epoch counter\n",
    "epoch = 0\n",
    "# number of epochs to train the model\n",
    "epochs = 50\n",
    "# initialize variables\n",
    "prev_mean_valid_loss = numpy.Inf\n",
    "start = 0\n",
    "# initialize error lists\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0  (in seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreas/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 \t Time: + 181.33974385261536 \t Training        loss:  0.4350694837858706 \t Validation loss:  0.3534855001938478\n",
      "Epoch:  4 \t Time: + 178.99992537498474 \t Training        loss:  0.3176764562921923 \t Validation loss:  0.32024289953204715\n",
      "Epoch:  6 \t Time: + 179.9589807987213 \t Training        loss:  0.2623137922678959 \t Validation loss:  0.3144400713901235\n",
      "Epoch:  8 \t Time: + 180.22914099693298 \t Training        loss:  0.22770063550444275 \t Validation loss:  0.31819723130208344\n",
      "Epoch:  10 \t Time: + 180.3503177165985 \t Training        loss:  0.20316295432909334 \t Validation loss:  0.32648086663907155\n",
      "Epoch:  12 \t Time: + 180.62848043441772 \t Training        loss:  0.18447468221565055 \t Validation loss:  0.33713888383546603\n",
      "\t\tStopping at epoch:  13 \tPrevious average Validation error was lower than                current Validation error\n"
     ]
    }
   ],
   "source": [
    "print('Time: ', start, ' (in seconds)')\n",
    "while not early_stopping and epoch < epochs:\n",
    "    if epoch == 0:\n",
    "        start = time.time()\n",
    "\n",
    "    # prep model for training\n",
    "    model.train()\n",
    "    for x_train, y_train in train_loader:\n",
    "        # forward pass\n",
    "        y_hat = model(x_train.to(device))\n",
    "        # calculate the loss\n",
    "        loss = criterion(y_hat.flatten(), y_train.to(device))\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss.append(loss.item())\n",
    "    # shut down autograd to begin evaluation\n",
    "    with torch.no_grad():\n",
    "        # prep model for evaluation\n",
    "        model.eval()\n",
    "        for x_val, y_val in val_loader:\n",
    "            # forward pass\n",
    "            y_hat = model(x_val.to(device))\n",
    "            # calculate the loss\n",
    "            loss = criterion(y_hat.flatten(), y_val.to(device))\n",
    "            # update running validation loss\n",
    "            valid_loss.append(loss.item())\n",
    "    # early stopping conditional\n",
    "    if prev_mean_valid_loss <= statistics.mean(valid_loss):\n",
    "        if consecutive is True:\n",
    "            prevent -= 1\n",
    "        consecutive = True\n",
    "        if prevent < 0:\n",
    "            early_stopping = True\n",
    "            message = '\\tPrevious average Validation error was lower than\\\n",
    "                current Validation error'\n",
    "    else:\n",
    "        consecutive = False\n",
    "\n",
    "    # print results after 2 epochs\n",
    "    if epoch % 2 == 1:\n",
    "        end = time.time()\n",
    "        print('Epoch: ', epoch+1, '\\t Time: +', end-start, '\\t Training\\\n",
    "        loss: ', statistics.mean(train_loss), '\\t Validation loss: ',\n",
    "              statistics.mean(valid_loss))\n",
    "        start = time.time()\n",
    "\n",
    "    # update epoch's validation loss variable\n",
    "    prev_mean_valid_loss = statistics.mean(valid_loss)\n",
    "\n",
    "    # early stopping message\n",
    "    if early_stopping is True:\n",
    "        print('\\t\\tStopping at epoch: ', epoch + 1, message)\n",
    "        epoch = epochs - 1\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTime: 2.376538515 \tTest Loss: 0.387354930504106\n"
     ]
    }
   ],
   "source": [
    "# define test error list\n",
    "test_loss = []\n",
    "# initialize timer\n",
    "start = time.time()\n",
    "# test model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        yhat = model(x.to(device))\n",
    "        loss = criterion(yhat.flatten(), y.to(device))\n",
    "        test_loss.append(loss.item())\n",
    "# end time checkpoint\n",
    "end = time.time()\n",
    "# print test results\n",
    "print('\\tTime: {:.10} \\tTest Loss: {:.15f}'.format(end-start,\n",
    "                                                   statistics.mean(test_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model's prediction on the whole dataset\n",
    "prediction = None\n",
    "with torch.no_grad():\n",
    "    prediction = model(x_test.to(device)).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_evaluation = []\n",
    "y_hat = []\n",
    "y_real = []\n",
    "column_list = []\n",
    "evaluation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    final_evaluation.append(y_test[i].numpy().max() - prediction[i].numpy().max())\n",
    "    column_list.append(numpy.argmax(y_test[i].numpy()) ==\n",
    "                       numpy.argmax(prediction[i].numpy()))\n",
    "    y_real.append(y_test[i].numpy().max())\n",
    "    y_hat.append(prediction[i].numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pandas.DataFrame(list(zip(final_evaluation, column_list,\n",
    "                                    y_real, y_hat)),\n",
    "                           columns=['loss_dif', 'column',\n",
    "                                    'y_real', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5233\n",
       "False     767\n",
       "Name: column, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.column.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_evaluation = []\n",
    "y_hat = []\n",
    "y_real = []\n",
    "column_list = []\n",
    "evaluation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model's prediction on the whole dataset\n",
    "overall = None\n",
    "with torch.no_grad():\n",
    "    overall = model(X.to(device)).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y)):\n",
    "    final_evaluation.append(Y[i].numpy().max() - overall[i].numpy().max())\n",
    "    column_list.append(numpy.argmax(Y[i].numpy()) ==\n",
    "                       numpy.argmax(overall[i].numpy()))\n",
    "    y_real.append(Y[i].numpy().max())\n",
    "    y_hat.append(overall[i].numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_df = pandas.DataFrame(list(zip(final_evaluation, column_list,\n",
    "                                    y_real, y_hat)),\n",
    "                           columns=['loss_dif', 'column',\n",
    "                                    'y_real', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     22617\n",
       "False     1383\n",
       "Name: column, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_df.column.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "del valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
